import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
import org.apache.flink.api.common.state.ListState;
import org.apache.flink.api.common.state.ListStateDescriptor;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.util.Collector;

import java.nio.file.Path;
import java.nio.file.Paths;
import java.nio.file.Files;
import java.util.ArrayList;
import java.util.List;
import java.time.LocalDate;

public class SingleJobSortExample {
    public static void main(String[] args) throws Exception {
        // Set up the streaming execution environment
        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        // List to store DataStreams from each file
        List<DataStream<Tuple2<String, String>>> dataStreams = new ArrayList<>();

        // Dynamically find all files with "xuortpgc" in the directory (replace with your path)
        String directoryPath = "path/to/directory"; // Update this to your directory
        List<Path> xuortpgcFiles = new ArrayList<>();
        Files.list(Paths.get(directoryPath))
            .filter(path -> path.getFileName().toString().toLowerCase().contains("xuortpgc"))
            .forEach(xuortpgcFiles::add);

        for (Path path : xuortpgcFiles) {
            String filename = path.getFileName().toString();
            System.out.println("Processing file: [" + filename + "]");

            // Read file into DataStream
            DataStream<String> lines = env.readTextFile(path.toString());

            // Process file into Tuple2 (date, filename)
            DataStream<Tuple2<String, String>> fileStream = lines
                .filter(line -> line.startsWith("#")) // Filter lines starting with "#"
                .map(line -> {
                    return new Tuple2<>(line.substring(0, 10), filename); // (date, filename)
                });

            dataStreams.add(fileStream);
        }

        // Combine all DataStreams into one
        DataStream<Tuple2<String, String>> combinedStream;
        if (!dataStreams.isEmpty()) {
            combinedStream = dataStreams.get(0);
            for (int i = 1; i < dataStreams.size(); i++) {
                combinedStream = combinedStream.union(dataStreams.get(i));
            }
        } else {
            throw new RuntimeException("No files found with 'xuortpgc' in the directory.");
        }

        // Sort the combined stream by f0 (date)
        DataStream<Tuple2<String, String>> sortedStream = combinedStream
            .keyBy(value -> "single_key") // Single key to collect all data
            .process(new SortByDateProcessFunction())
            .setParallelism(1); // Ensure sorting happens in one task

        // Rest of your application continues here
        sortedStream.print(); // Replace with your downstream logic

        // Execute the job
        env.execute("Single Job with Sorted Static Input");
    }

    public static class SortByDateProcessFunction extends KeyedProcessFunction<String, Tuple2<String, String>, Tuple2<String, String>> {
        private transient ListState<Tuple2<String, String>> buffer;
        private boolean hasEmitted = false;

        @Override
        public void open(Configuration parameters) throws Exception {
            ListStateDescriptor<Tuple2<String, String>> descriptor =
                new ListStateDescriptor<>("buffer", Tuple2.class);
            buffer = getRuntimeContext().getListState(descriptor);
        }

        @Override
        public void processElement(Tuple2<String, String> value, Context ctx, Collector<Tuple2<String, String>> out) throws Exception {
            // Buffer all incoming elements
            buffer.add(value);

            // Register a timer to emit results after a short delay (to ensure all data is read)
            ctx.timerService().registerProcessingTimeTimer(ctx.timerService().currentProcessingTime() + 1000);
        }

        @Override
        public void onTimer(long timestamp, OnTimerContext ctx, Collector<Tuple2<String, String>> out) throws Exception {
            if (!hasEmitted) {
                List<Tuple2<String, String>> allData = new ArrayList<>();
                for (Tuple2<String, String> item : buffer.get()) {
                    allData.add(item);
                }

                // Sort by f0 (date) from oldest to newest
                allData.sort((t1, t2) -> LocalDate.parse(t1.f0).compareTo(LocalDate.parse(t2.f0)));

                // Emit sorted data downstream
                for (Tuple2<String, String> item : allData) {
                    out.collect(item);
                }

                hasEmitted = true; // Prevent re-emission
                buffer.clear(); // Clean up state
            }
        }
    }
}



import org.apache.flink.api.common.state.ListState;
import org.apache.flink.api.common.state.ListStateDescriptor;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
import org.apache.flink.util.Collector;

import java.time.LocalDate;
import java.util.ArrayList;
import java.util.List;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public static class SortByDateProcessFunction extends KeyedProcessFunction<String, Tuple2<String, String>, Tuple2<String, String>> {
    private static final Logger LOG = LoggerFactory.getLogger(SortByDateProcessFunction.class);
    private transient ListState<Tuple2<String, String>> buffer;
    private boolean hasEmitted = false;

    @Override
    public void open(Configuration parameters) throws Exception {
        ListStateDescriptor<Tuple2<String, String>> descriptor =
            new ListStateDescriptor<>("buffer", Tuple2.class);
        buffer = getRuntimeContext().getListState(descriptor);
        LOG.info("Initialized ListState buffer");
    }

    @Override
    public void processElement(Tuple2<String, String> value, Context ctx, Collector<Tuple2<String, String>> out) throws Exception {
        LOG.info("Adding element to buffer: {}", value);
        buffer.add(value);

        // Register a timer to emit results after a short delay
        long currentTime = ctx.timerService().currentProcessingTime();
        ctx.timerService().registerProcessingTimeTimer(currentTime + 1000);
        LOG.info("Registered timer for timestamp: {}", currentTime + 1000);
    }

    @Override
    public void onTimer(long timestamp, OnTimerContext ctx, Collector<Tuple2<String, String>> out) throws Exception {
        LOG.info("Timer triggered at timestamp: {}", timestamp);
        if (!hasEmitted) {
            List<Tuple2<String, String>> allData = new ArrayList<>();
            LOG.info("Starting to retrieve elements from buffer");
            for (Tuple2<String, String> item : buffer.get()) {
                if (item != null) {
                    allData.add(item);
                    LOG.info("Retrieved from buffer: {}", item);
                } else {
                    LOG.warn("Found null element in buffer");
                }
            }
            LOG.info("Total elements retrieved: {}", allData.size());

            if (!allData.isEmpty()) {
                // Sort by f0 (date) from oldest to newest
                allData.sort((t1, t2) -> LocalDate.parse(t1.f0).compareTo(LocalDate.parse(t2.f0)));
                LOG.info("Sorted {} elements", allData.size());

                // Emit sorted data downstream
                for (Tuple2<String, String> item : allData) {
                    out.collect(item);
                    LOG.info("Emitted sorted element: {}", item);
                }


adding ------- count

public static class SortByDateProcessFunction extends KeyedProcessFunction<String, Tuple2<String, String>, Tuple2<String, String>> {
    private static final Logger LOG = LoggerFactory.getLogger(SortByDateProcessFunction.class);
    private transient ListState<Tuple2<String, String>> buffer;
    private transient ValueState<Integer> elementCount;
    private boolean hasEmitted = false;
    private static final int EXPECTED_ELEMENTS = 200; // Adjust based on your estimate (10 files × 20 lines)

    @Override
    public void open(Configuration parameters) throws Exception {
        ListStateDescriptor<Tuple2<String, String>> descriptor =
            new ListStateDescriptor<>("buffer", Tuple2.class);
        buffer = getRuntimeContext().getListState(descriptor);

        ValueStateDescriptor<Integer> countDescriptor =
            new ValueStateDescriptor<>("elementCount", Integer.class, 0);
        elementCount = getRuntimeContext().getState(countDescriptor);

        LOG.info("Initialized ListState buffer and element counter");
    }

    @Override
    public void processElement(Tuple2<String, String> value, Context ctx, Collector<Tuple2<String, String>> out) throws Exception {
        LOG.info("Adding element to buffer: {}", value);
        buffer.add(value);

        // Increment the counter
        int newCount = elementCount.value() + 1;
        elementCount.update(newCount);
        LOG.info("Current element count: {}", newCount);

        // Emit once we’ve seen all expected elements
        if (newCount >= EXPECTED_ELEMENTS && !hasEmitted) {
            emitSortedData(out);
        }
    }

    private void emitSortedData(Collector<Tuple2<String, String>> out) throws Exception {
        List<Tuple2<String, String>> allData = new ArrayList<>();
        LOG.info("Starting to retrieve elements from buffer");
        for (Tuple2<String, String> item : buffer.get()) {
            if (item != null) {
                allData.add(item);
                LOG.info("Retrieved from buffer: {}", item);
            } else {
                LOG.warn("Found null element in buffer");
            }
        }
        LOG.info("Total elements retrieved: {}", allData.size());

        if (!allData.isEmpty()) {
            // Sort by f0 (date) from oldest to newest
            allData.sort((t1, t2) -> LocalDate.parse(t1.f0).compareTo(LocalDate.parse(t2.f0)));
            LOG.info("Sorted {} elements", allData.size());

            // Emit sorted data downstream
            for (Tuple2<String, String> item : allData) {
                out.collect(item);
                LOG.info("Emitted sorted element: {}", item);
            }
        } else {
            LOG.warn("No elements to sort in buffer");
        }

        hasEmitted = true; // Prevent re-emission
        buffer.clear(); // Clean up state
        LOG.info("Cleared buffer and marked as emitted");
    }
}
            } else {
                LOG.warn("No elements to sort in buffer");
            }

            hasEmitted = true; // Prevent re-emission
            buffer.clear(); // Clean up state
            LOG.info("Cleared buffer and marked as emitted");
        } else {
            LOG.info("Already emitted, skipping further processing");
        }
    }
}


_------- without timer option
import org.apache.flink.api.common.state.ListState;
import org.apache.flink.api.common.state.ListStateDescriptor;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
import org.apache.flink.util.Collector;

import java.time.LocalDate;
import java.util.ArrayList;
import java.util.List;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public static class SortByDateProcessFunction extends KeyedProcessFunction<String, Tuple2<String, String>, Tuple2<String, String>> {
    private static final Logger LOG = LoggerFactory.getLogger(SortByDateProcessFunction.class);
    private transient ListState<Tuple2<String, String>> buffer;
    private boolean hasEmitted = false;

    @Override
    public void open(Configuration parameters) throws Exception {
        ListStateDescriptor<Tuple2<String, String>> descriptor =
            new ListStateDescriptor<>("buffer", Tuple2.class);
        buffer = getRuntimeContext().getListState(descriptor);
        LOG.info("Initialized ListState buffer");
    }

    @Override
    public void processElement(Tuple2<String, String> value, Context ctx, Collector<Tuple2<String, String>> out) throws Exception {
        LOG.info("Adding element to buffer: {}", value);
        buffer.add(value);

        // No timer needed—rely on end-of-input
    }

    @Override
    public void onTimer(long timestamp, OnTimerContext ctx, Collector<Tuple2<String, String>> out) throws Exception {
        // This will not be used since we’re avoiding timers
        LOG.info("Timer triggered at timestamp: {} (unexpected)", timestamp);
    }

    @Override
    public void close() throws Exception {
        if (!hasEmitted) {
            LOG.info("close() called, preparing to sort and emit");
            List<Tuple2<String, String>> allData = new ArrayList<>();
            for (Tuple2<String, String> item : buffer.get()) {
                if (item != null) {
                    allData.add(item);
                    LOG.info("Retrieved from buffer: {}", item);
                } else {
                    LOG.warn("Found null element in buffer");
                }
            }
            LOG.info("Total elements retrieved: {}", allData.size());

            if (!allData.isEmpty()) {
                // Sort by f0 (date) from oldest to newest
                allData.sort((t1, t2) -> LocalDate.parse(t1.f0).compareTo(LocalDate.parse(t2.f0)));
                LOG.info("Sorted {} elements", allData.size());

                // Emit sorted data downstream
                for (Tuple2<String, String> item : allData) {
                    out.collect(item);
                    LOG.info("Emitted sorted element: {}", item);
                }
            } else {
                LOG.warn("No elements to sort in buffer");
            }

            hasEmitted = true; // Prevent re-emission
            buffer.clear(); // Clean up state
            LOG.info("Cleared buffer and marked as emitted");
        }
        super.close();
    }
}
